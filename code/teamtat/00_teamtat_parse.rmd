---
title: "teamtat XML data post-processing"
author: "Dominick J. Lemas"
date: "06/07/2021"
output: html_document

---

```{r, include=FALSE}
##-------------- 
# **************************************************************************** #
# ***************                Project Overview              *************** #
# **************************************************************************** #

# Author:            Dominick Lemas 
# Start Date:        June 07, 2021 
# Last Modified:      
# IRB:               UFHealth  
#                    
#
# version: R version 4.0.3 (2020-10-10)
# version: Rstudio version Version 1.3.1073 

# **************************************************************************** #
# ***************                Objective                     *************** #
# **************************************************************************** #

#  (1) Descriptive statistics on teamtat output. 
#  (2) Outputs for downstream analysis that includes import-ready files for CLAMP. 

# https://stackoverflow.com/questions/17198658/how-to-parse-xml-to-r-data-frame
# https://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML
# # https://stackoverflow.com/questions/44230413/python-r-generate-dataframe-from-xml-when-not-all-nodes-contain-all-variables

```

#### __Data Processing Summary__
![](dataprocessing_workflow.png)
The data processing workflow . . . 
the fisrt step is X and second setep is y and the final step is Z. 

```{r, include=FALSE, echo=FALSE}

# **************************************************************************** #
# ***************                Libraries                     *************** #
# **************************************************************************** #

library(xml2)
library(XML) 
library(plyr)
library(tidyverse)
library(stringr)

```

```{r, warning=FALSE, echo=FALSE}

# DIRECTORY WITH FILES

files <- list.files(path="~/mombaby-ehr-nlp/data/xml/", 
                    pattern=".xml", 
                    all.files=TRUE,
                    full.names=TRUE)

```

```{r, warning=FALSE, echo=FALSE}

# extract annotations
file_count=length(files)

# loop through annotations
for(i in 1:file_count) {

  # loop through each annotation`
  file_index=files[[i]]

# EXTRACT DATA FROM XML

# import data
x <- read_xml(file_index)

# DESCRIPTIVE FUNCTIONS
# xml_name(x)
# xml_children(x)
# xml_text(x)

# create empty tibble() for data
feed_status <- tibble(
  note_id= character(),
  annotation_id = character(),
  class = character(),
  identifier = character(),
  annotator = character(),
  date = character(),
  offset = numeric(),
  length = numeric(),
  text = character()
)

# extract note ID
passage=xml_find_all(x, "//passage/text") %>% xml_text(trim=TRUE) %>% as_tibble()
note_id_all=last(passage$value)
note_id_tmp=str_replace_all(note_id_all, fixed(" "), "") 
note_id_tmp1=str_replace_all(note_id_tmp, fixed(":"), "_")
note_id_final=str_replace_all(note_id_tmp1, fixed(","), "_")

# extract annotations
annotate=xml_find_all(x, "//annotation")
clinical_note=passage[[1]][1]

# extract annotations
index=length(annotate)

# loop through annotations
for(i in 1:index) {

  # loop through each annotation`
  annotate_index=annotate[[i]]
  
  # ID
  annotate_id=xml_attr(annotate_index, "id")
  
  # ANNOTATION
  annotate_all=xml_find_all(annotate_index, "infon")
  attr=xml_attr(annotate_all, "key")
  text=xml_text(annotate_all,trim=TRUE)
  annotate_merge=as_tibble(cbind(attr,text))

  # LOCATION
  location_all=as_tibble(unlist(xml_attrs(xml_find_all(annotate_index, "location"))))
  offset=as.numeric(location_all[1,1])
  length=as.numeric(location_all[2,1])
  
  # TEXT
  text_all=xml_find_all(annotate_index, "text") %>% xml_text(trim=TRUE)

    # import to tibble
    feed_status[i,1]=note_id_final
    feed_status[i,2]=annotate_id
    feed_status[i,3]=annotate_merge %>% filter(attr=="type") %>% select(text)
    feed_status[i,4]=annotate_merge %>% filter(attr=="identifier") %>% select(text)
    feed_status[i,5]=annotate_merge %>% filter(attr=="annotator") %>% select(text)
    feed_status[i,6]=annotate_merge %>% filter(attr=="updated_at") %>% select(text)
    feed_status[i,7]=offset 
    feed_status[i,8]=length
    feed_status[i,9]=text_all
   
  }

# feed_status output
feed_status

# annotation output
class=feed_status %>% filter(class=="FEED_CLASS") %>% select(text) %>% rename(., class = text)
clinical_note
note=list(class,clinical_note,feed_status)

# file name
file_name=paste0(feed_status$note_id[1],".rda")
data_directory=paste0("~/mombaby-ehr-nlp/data/rda/") 
data_path=paste0(data_directory,file_name)

# export
note %>% save(note, file=data_path)

}


                              
```

```{r, include=FALSE, echo=FALSE}

# OUTPUT AS BRAT FORMAT
# https://brat.nlplab.org/standoff.html

# Example
# T1	Organization 0 4	Sony
# T2	MERGE-ORG 14 27	joint venture

# DESIRED OUTPUT
# T1	MESH:D0019 21 4	latching baby to both breasts
# T2	MESH:D0019 14 27	joint venture

# BRAT output

feed_status_brat=feed_status %>% mutate( start=offset, 
                                    end=offset+length) %>%
                            mutate(unique_id=case_when(class == "FEED_STATUS" ~ "T1",
                                    class == "FEED_CLASS" ~ "T2"))
                                                       

feed_status_brat %>%
  select(unique_id, identifier, start, end, text) %>%
  write_tsv(., path="../data/processed/xml_parsed/", col_names=FALSE)



```


